{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b28eaac0-b25e-41fa-96a9-b518f154351f",
   "metadata": {},
   "source": [
    "## Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an example of each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cc6497-f09c-4293-959d-1769d52ca5c4",
   "metadata": {},
   "source": [
    "### Simple linear regression has only one x and one y variable. Multiple linear regression has one y and two or more x variables.  \n",
    "### For instance, when we predict rent based on square feet alone that is simple linear regression. When we predict rent based on square feet and age of the building that is an example of multiple linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809ac4ba-a801-4eb8-9bf8-93b98af31284",
   "metadata": {},
   "source": [
    "## Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135b3d67-4999-4361-8d61-fac1f4127e62",
   "metadata": {},
   "source": [
    "### There are primarily five assumptions of linear regression. They are:\n",
    "\n",
    "1. There is a linear relationship between the predictors (x) and the outcome (y)\n",
    "2. Predictors (x) are independent and observed with negligible error\n",
    "3. Residual Errors have a mean value of zero\n",
    "4. Residual Errors have constant variance\n",
    "5. Residual Errors are independent from each other and predictors (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5ec1a6-73ed-4934-94ce-6bc2c2c76d51",
   "metadata": {},
   "source": [
    "### \n",
    "1. We can check the linearity of the data by looking at the Residual vs Fitted plot.\n",
    "2. The easiest way to check the assumption of independence is using the Durbin-Watson test.\n",
    "3. We can easily check this assumption by looking at the same residual vs fitted plot. We would ideally want to see the red line flat on 0, which would indicate that the residual errors have a mean value of zero.\n",
    "4. We can check this assumption using the Scale-Location plot. In this plot we can see the fitted values vs the square root of the standardized residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7407c4f-dbb0-473d-8fb4-03b9e88b600d",
   "metadata": {},
   "source": [
    "## Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b4a97c-d2dc-4e2d-912c-063f32436998",
   "metadata": {},
   "source": [
    "### Intercept in linear regression will interpret the value of dependent variable when independent variables are 0. And slope will be interpreted as for a unit increase in independent variables, the change in dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275c78a6-5380-4a08-9405-eb3e68f6ae86",
   "metadata": {},
   "source": [
    "## Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a064a39f-7aaa-489a-9764-daa9ba20c02c",
   "metadata": {},
   "source": [
    "### Gradient Descent is known as one of the most commonly used optimization algorithms to train machine learning models by means of minimizing errors between actual and expected results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37307c83-8629-49aa-9261-15f067b35475",
   "metadata": {},
   "source": [
    "### The main objective of using a gradient descent algorithm is to minimize the cost function using iteration. To achieve this goal, it performs two steps iteratively:\n",
    "1. Calculates the first-order derivative of the function to compute the gradient or slope of that function.\n",
    "2. Move away from the direction of the gradient, which means slope increased from the current point by alpha times, where Alpha is defined as Learning Rate. It is a tuning parameter in the optimization process which helps to decide the length of the steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a77c1c-53a3-4a51-8334-3ab6e0ba7710",
   "metadata": {},
   "source": [
    "## Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dc0082-24c4-46f7-b59e-fed2cd1a2c02",
   "metadata": {},
   "source": [
    "### Multiple linear regression is a regression model that estimates the relationship between a quantitative dependent variable and two or more independent variables using a straight line.\n",
    "### In linear regress only has one independent variable impacting the slope of the relationship, multiple regression incorporates multiple independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa36497a-3bf2-4a2d-9865-38d461405bd1",
   "metadata": {},
   "source": [
    "## Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and address this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869a2902-ed1e-43a8-a3d0-cbe97b298540",
   "metadata": {},
   "source": [
    "### Multicollinearity occurs when two or more independent variables in a data frame have a high correlation with one another in a regression model.\n",
    "### Variance Inflation Factor (VIF) or calculating the correlation matrix of the independent variables to address multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7036efd0-0b1e-4ddd-94f6-bd0bb96a2828",
   "metadata": {},
   "source": [
    "## Q7. Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420b57bd-0a7e-4602-8577-52ebbbb1a818",
   "metadata": {},
   "source": [
    "### A polynomial model is a type of regression model in which the relationship between the dependent variable and the independent variable(s) is modeled as an nth-degree polynomial function. In other words, instead of fitting a straight line (as in linear regression), a curve fits the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7b5692-5757-4c3c-a8f0-1338219e9b51",
   "metadata": {},
   "source": [
    "## Q8. What are the advantages and disadvantages of polynomial regression compared to linear regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2aef3f1-420d-4041-b458-e21932d7416c",
   "metadata": {},
   "source": [
    "### Advantages of using Polynomial Regression:\n",
    "1. Polynomial provides the best approximation of the relationship between the dependent and independent variable.\n",
    "2. A Broad range of function can be fit under it.\n",
    "3. Polynomial basically fits a wide range of curvature.\n",
    "\n",
    "### Disadvantages of using Polynomial Regression:\n",
    "1. The presence of one or two outliers in the data can seriously affect the results of the nonlinear analysis.\n",
    "2. These are too sensitive to the outliers.\n",
    "3. In addition, there are unfortunately fewer model validation tools for the detection of outliers in nonlinear regression than there are for linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce79a9a-efbc-4be3-b773-873f2a6c4b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
